{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "import constants\n",
    "\n",
    "from azure.ai.ml import command, Input, Output\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import Environment\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "# Get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=constants.SUBSCRIPTION_ID,\n",
    "    resource_group_name=constants.RESOURCE_GROUP_NAME,\n",
    "    workspace_name=constants.WORKSPACE_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {\n",
    "    \"TXN\": {\n",
    "        \"name\": [\n",
    "            \"Texas Instruments Incorporated (<b>TXN</b>) May Have A Gold Mine.\",\n",
    "            \"Unusual Call Option Trade in Texas Instruments (<b>TXN</b>) Worth $1,995.00K\",\n",
    "            \"What&#39;s in the Offing for Texas Instruments (<b>TXN</b>) in Q2 Earnings?\",\n",
    "            \"Mizuho Maintains Texas Instruments (<b>TXN</b>) Neutral Recommendation\",\n",
    "            \"Texas Instruments Unusual Options Activity\",\n",
    "            \"Texas Instruments Incorporated (<b>TXN</b>) Stock Records 2.47% Quarterly Movement\",\n",
    "            \"Selling Your Texas Instruments Incorporated (NASDAQ: <b>TXN</b>) Stock? Here\\u2019s What You Need To Know\",\n",
    "            \"Texas Instruments board declares third quarter 2023 quarterly dividend\"\n",
    "        ],\n",
    "        \"description\": [\n",
    "            \"Texas Instruments Incorporated (NASDAQ:TXN) price on Friday, July 21, rose 2.45% above its previous day\\u2019s close as an upside momentum from buyers pushed the stock\\u2019s value to $184.32. A look at the stock\\u2019s price movement,\",\n",
    "            \"On July 21, 2023 at 15:50:03 ET an unusually large $1,995.00K block of Call contracts in Texas Instruments (<b>TXN</b>) was bought, with a strike price of $200.00 / share, expiring in 182 day(s) (on January 19, 2024). Fintel tracks all large options trades ...\",\n",
    "            \"Texas Instruments&#39; (TXN) second-quarter 2022 results are likely to reflect the adverse effects of inventory reduction on Analog and Embedded Processing segments.\",\n",
    "            \"Fintel reports that on July 20, 2023, Mizuho maintained coverage of Texas Instruments (NASDAQ:<b>TXN</b>) with a Neutral recommendation. Analyst Price Forecast Suggests 2.51% Upside As of July 6, 2023, the average one-year price target for Texas Instruments is ...\",\n",
    "            \"In terms of liquidity and interest, the mean open interest for Texas Instruments options trades today is 1554.12 with a total volume of 1,617.00.\",\n",
    "            \"The stock of Texas Instruments Incorporated (TXN) has gone up by 2.21% for the week, with a 3.55% rise in the past month and a 2.47% rise in the past quarter. The volatility ratio for the week is 1.84%,\",\n",
    "            \"Texas Instruments Incorporated (NASDAQ:TXN) shares, rose in value on Friday, July 07, with the stock price up by 0.48% to the previous day\\u2019s close as strong demand from buyers drove the stock to $175.\",\n",
    "            \"The board of directors of Texas Instruments Incorporated (NASDAQ:TXN) today declared a quarterly cash dividend of $1.24 per share of common stock, payable August 15, 2023, to\"\n",
    "        ],\n",
    "        \"datePublished\": [\n",
    "            \"2023-07-22T15:36:00.0000000Z\",\n",
    "            \"2023-07-22T15:36:00.0000000Z\",\n",
    "            \"2023-07-20T14:53:00.0000000Z\",\n",
    "            \"2023-07-21T15:44:00.0000000Z\",\n",
    "            \"2023-07-20T20:45:00.0000000Z\",\n",
    "            \"2023-07-18T07:04:00.0000000Z\",\n",
    "            \"2023-07-07T20:37:00.0000000Z\",\n",
    "            \"2023-07-20T21:28:00.0000000Z\"\n",
    "        ],\n",
    "        \"url\": [\n",
    "            \"https://stocksregister.com/2023/07/22/texas-instruments-incorporated-txn-may-have-a-gold-mine/\",\n",
    "            \"https://www.msn.com/en-us/money/companies/unusual-call-option-trade-in-texas-instruments-txn-worth-199500k/ar-AA1ecS2j\",\n",
    "            \"https://finance.yahoo.com/news/whats-offing-texas-instruments-txn-145300746.html\",\n",
    "            \"https://www.msn.com/en-us/money/companies/mizuho-maintains-texas-instruments-txn-neutral-recommendation/ar-AA1eaZS9\",\n",
    "            \"https://www.benzinga.com/markets/options/23/07/33312387/texas-instruments-unusual-options-activity\",\n",
    "            \"https://newsheater.com/2023/07/18/texas-instruments-incorporated-txn-stock-records-2-47-quarterly-movement/\",\n",
    "            \"https://stocksregister.com/2023/07/07/selling-your-texas-instruments-incorporated-nasdaq-txn-stock-heres-what-you-need-to-know/\",\n",
    "            \"https://www.benzinga.com/pressreleases/23/07/n33313116/texas-instruments-board-declares-third-quarter-2023-quarterly-dividend\"\n",
    "        ],\n",
    "        \"texts\": [\n",
    "            \"Texas Instruments Incorporated (NASDAQ:TXN) price on Friday, July 21, rose 2.45% above its previous day\\u2019s close as an upside momentum from buyers pushed the stock\\u2019s value to $184.32. A look at the stock\\u2019s price movement, the close in the last trading session was $179.92, moving within a range at $181.355 and $185.57. The PE ratio in trailing twelve months stood at 20.68. Turning to its 52-week performance, $186.30 and $145.97 were the 52-week high and 52-week low respectively. Overall, TXN moved 8.12% over the past month. Top 5 AI Stocks to Buy for 2023 The artificial intelligence (AI) revolution is\",\n",
    "            \"\",\n",
    "            \"Texas Instruments Incorporated TXN is scheduled to report second-quarter 2023 results on Jul 25. For second-quarter 2023, Texas Instruments expects revenues between $4.17 billion and $4.53 billion. The Zacks Consensus Estimate is pegged at $4.36 billion, suggesting a decline of 16.4% from the year-ago quarter\\u2019s reported figure. Management expects earnings of $1.62-$1.88 per share for the quarter under review. The consensus mark is pegged at $1.76 per share, indicating a fall of 28.2% from the prior-year quarter\\u2019s reported figure. The estimate has remained unchanged over the past 30 days. TXN\\u2019s earnings surpassed the Zacks Consensus Estimate in all the trailing\",\n",
    "            \"\",\n",
    "            \"A whale with a lot of money to spend has taken a noticeably bearish stance on Texas Instruments. Looking at options history for Texas Instruments TXN we detected 14 strange trades. If we consider the specifics of each trade, it is accurate to state that 35% of the investors opened trades with bullish expectations and 64% with bearish. From the overall spotted trades, 6 are puts, for a total amount of $667,765 and 8, calls, for a total amount of $379,357. What's The Price Target? Taking into account the Volume and Open Interest on these contracts, it appears that whales\",\n",
    "            \"The stock of Texas Instruments Incorporated (TXN) has gone up by 2.21% for the week, with a 3.55% rise in the past month and a 2.47% rise in the past quarter. The volatility ratio for the week is 1.84%, and the volatility levels for the past 30 days are 1.92% for TXN. The simple moving average for the last 20 days is 4.02% for TXN stock, with a simple moving average of 6.86% for the last 200 days. Is It Worth Investing in Texas Instruments Incorporated (NASDAQ: TXN) Right Now? Texas Instruments Incorporated (NASDAQ: TXN) has a higher price-to-earnings ratio\",\n",
    "            \"Texas Instruments Incorporated (NASDAQ:TXN) shares, rose in value on Friday, July 07, with the stock price up by 0.48% to the previous day\\u2019s close as strong demand from buyers drove the stock to $175.66. Actively observing the price movement in the recent trading, the stock is buoying the session at $174.82, falling within a range of $173.08 and $175.48. The value of beta (5-year monthly) is 1.02 whereas the PE ratio is 19.62 over 12-month period. Referring to stock\\u2019s 52-week performance, its high was $186.30, and the low was $145.97. On the whole, TXN has fluctuated by 3.11% over the\",\n",
    "            \"DALLAS, July 20, 2023 /PRNewswire/ -- The board of directors of Texas Instruments Incorporated TXN today declared a quarterly cash dividend of $1.24 per share of common stock, payable August 15, 2023, to stockholders of record on July 31, 2023. About Texas Instruments Texas Instruments Incorporated TXN is a global semiconductor company that designs, manufactures, tests and sells analog and embedded processing chips for markets such as industrial, automotive, personal electronics, communications equipment and enterprise systems. Our passion to create a better world by making electronics more affordable through semiconductors is alive today, as each generation of innovation builds upon\"\n",
    "        ],\n",
    "    }\n",
    "}\n",
    "\n",
    "dict2 = {\n",
    "    \"DOCN\": {\n",
    "        \"name\": [\n",
    "            \"DigialOCean did something\",\n",
    "            \"DigialOCean did soemthing\"\n",
    "        ],\n",
    "        \"description\": [\n",
    "            \"DigialOCean did something\",\n",
    "            \"DigialOCean did soemthing\"\n",
    "        ],\n",
    "        \"datePublished\": [\n",
    "            \"DigialOCean did something\",\n",
    "            \"DigialOCean did soemthing\"\n",
    "        ],\n",
    "        \"url\": [\n",
    "            \"DigialOCean did something\",\n",
    "            \"DigialOCean did soemthing\"\n",
    "        ],\n",
    "        \"texts\": [\n",
    "            \"DigialOCean did something\",\n",
    "            \"DigialOCean did soemthing\"\n",
    "        ],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict = {}\n",
    "\n",
    "dict_list = [dict1, dict2]\n",
    "for item in dict_list: \n",
    "    all_dict.update(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting components/prep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile components/prep.py \n",
    "\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "# Check if given credential can get token successfully.\n",
    "credential.get_token(\"https://management.azure.com/.default\")\n",
    "secret_client = SecretClient(vault_url=\"https://mlgroup.vault.azure.net/\", credential=credential)\n",
    "\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(\"prep\")\n",
    "parser.add_argument(\"--blob_storage\", type=str, help=\"Mounted Azure ML blob storage\")\n",
    "parser.add_argument(\"--prep_output\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "# log in to the Blob Service Client\n",
    "blob_storage = args.blob_storage\n",
    "blob_storage_key = secret_client.get_secret(\"blob-storage-key\")\n",
    "blob_service_client = BlobServiceClient(blob_storage, account_key=blob_storage_key.value)\n",
    "\n",
    "# connect to the container \n",
    "container_client = blob_service_client.get_container_client(container=\"stock-news-json\") \n",
    "\n",
    "# list and download all currently available blobs\n",
    "blob_list = container_client.list_blobs()\n",
    "print(f\"Blob from: {blob_storage} has these blobs today: {blob_list}\")\n",
    "\n",
    "# get the timestamp with the current day \n",
    "current_day_date = datetime.datetime.today().isoformat()[:10]\n",
    "\n",
    "blobs_to_use = [blob.name for blob in blob_list if current_day_date in blob.name]\n",
    "for blob in blobs_to_use:\n",
    "      print(f\"Downloading blob: {blob}\")\n",
    "      blob_client = blob_service_client.get_blob_client(container=\"stock-news-json\", blob=blob)\n",
    "      with open(blob, mode=\"wb\") as sample_blob:\n",
    "            download_stream = blob_client.download_blob()\n",
    "            sample_blob.write(download_stream.readall())\n",
    "\n",
    "all_data_dict = {}\n",
    "for json_file in blobs_to_use:\n",
    "      with open(json_file,\"r+\") as file:\n",
    "      # First we load existing data into a dict.\n",
    "            file_data = json.load(file)\n",
    "            all_data_dict.update(file_data)\n",
    "            \n",
    "with open((Path(args.prep_output) / \"merged_stock_news.json\"), \"w\") as file:\n",
    "      file.write(json.dumps(all_data_dict, indent=4))\n",
    "\n",
    "# this is a comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting components/classify.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile components/classify.py\n",
    "\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--classify_input\", type=str, help=\"Mounted Azure ML blob storage\")\n",
    "parser.add_argument(\"--classify_output\", type=str, help=\"Mounted Azure ML blob storage\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "# download distilbert model from HuggingFace\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"KernAI/stock-news-destilbert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"KernAI/stock-news-destilbert\")\n",
    "\n",
    "# retriev the list of blobs from the current day - input is a .txt file\n",
    "with open(os.path.join(args.classify_input, \"merged_stock_news.json\"), \"r\") as f:\n",
    "      data = json.load(f)\n",
    "\n",
    "# get a list of all tickers in the data   \n",
    "tickers = list(data.keys())\n",
    "for ticker in tickers:\n",
    "      texts = data[ticker][\"texts\"]\n",
    "      sentiments = []\n",
    "      for text in texts: \n",
    "            tokenized_text = tokenizer(\n",
    "                  text,\n",
    "                  truncation=True,\n",
    "                  is_split_into_words=False,\n",
    "                  return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            outputs = model(tokenized_text[\"input_ids\"])\n",
    "            outputs_logits = outputs.logits.argmax(1)\n",
    "\n",
    "            mapping = {0: 'neutral', 1: 'negative', 2: 'positive'}\n",
    "            predicted_label = mapping[int(outputs_logits[0])]\n",
    "            sentiments.append(predicted_label)\n",
    "\n",
    "      # add the sentiments to the data\n",
    "      data[ticker][\"sentiments\"] = sentiments\n",
    "\n",
    "# overwrite old files with new files containing the sentiment\n",
    "with open((Path(args.classify_output) / \"merged_stock_news.json\"), \"w\") as f:\n",
    "      json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting components/summarize.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile components/summarize.py\n",
    "\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "\n",
    "from pathlib import Path\n",
    "import datetime \n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration, TFPegasusForConditionalGeneration\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "# Check if given credential can get token successfully.\n",
    "credential.get_token(\"https://management.azure.com/.default\")\n",
    "secret_client = SecretClient(vault_url=\"https://mlgroup.vault.azure.net/\", credential=credential)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--summarize_input\", type=str, help=\"Mounted Azure ML blob storage\")\n",
    "parser.add_argument(\"--summarize_output\", type=str, help=\"Mounted Azure ML blob storage\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "# load the model and the tokenizer\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"human-centered-summarization/financial-summarization-pegasus\")\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"human-centered-summarization/financial-summarization-pegasus\") \n",
    "\n",
    "# retriev the list of blobs from the current day - input is a .txt file\n",
    "with open(os.path.join(args.summarize_input, \"merged_stock_news.json\"), \"r\") as f:\n",
    "      data = json.load(f)\n",
    "\n",
    "tickers = list(data.keys())\n",
    "for ticker in tickers:\n",
    "      texts = data[ticker][\"texts\"]\n",
    "\n",
    "      summaries = []\n",
    "      for text in texts: \n",
    "            # Tokenize our text\n",
    "            # If you want to run the code in Tensorflow, please remember to return the particular tensors as simply as using return_tensors = 'tf'\n",
    "            input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "            # Generate the output (Here, we use beam search but you can also use any other strategy you like)\n",
    "            output = model.generate(\n",
    "                  input_ids, \n",
    "                  max_length=32, \n",
    "                  num_beams=5, \n",
    "                  early_stopping=True\n",
    "            )\n",
    "\n",
    "            # Finally, we can print the generated summary\n",
    "            summaries.append(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "\n",
    "      # add the sentiments to the data\n",
    "      data[ticker][\"summaries\"] = summaries\n",
    "      \n",
    "data = json.dumps(data)\n",
    "\n",
    "# connect and authenticate to the blob client\n",
    "account_url = \"https://mlstorageleo.blob.core.windows.net\"\n",
    "file_name = f\"processed-stock-news-{datetime.datetime.today().isoformat()[:10]}.json\"\n",
    "\n",
    "# Create the BlobServiceClient object\n",
    "blob_storage_key = secret_client.get_secret(\"blob-storage-key\")\n",
    "blob_service_client = BlobServiceClient(account_url, credential=blob_storage_key.value)\n",
    "blob_client = blob_service_client.get_blob_client(container=\"processed-stock-news-json\", blob=file_name)\n",
    "blob_client.upload_blob(data)\n",
    "\n",
    "# overwrite old files with new files containing the sentiment\n",
    "with open((Path(args.summarize_output) / \"merged_stock_news.json\"), \"w\") as f:\n",
    "      json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dependencies/conda.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile dependencies/conda.yml\n",
    "name: stock-analysis-env\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.9\n",
    "  - pip\n",
    "  - pip:\n",
    "    - azure-storage-blob\n",
    "    - azure-identity\n",
    "    - azure-keyvault\n",
    "    - transformers\n",
    "    - torch\n",
    "    - sentencepiece\n",
    "    - numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_env_name = \"stock-analysis-env\"\n",
    "version = \"1.6\"\n",
    "\n",
    "try:    \n",
    "    pipeline_job_env = ml_client.environments.get(custom_env_name, version=version)\n",
    "\n",
    "except:\n",
    "    pipeline_job_env = Environment(\n",
    "        name=custom_env_name,\n",
    "        description=\"Custom environment for stock analysis pipeline\",\n",
    "        conda_file=os.path.join(\"dependencies\", \"conda.yml\"),\n",
    "        image=\"mcr.microsoft.com/azureml/curated/python-sdk-v2:4\",\n",
    "        version=version,\n",
    "    )\n",
    "    pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
    "\n",
    "    print(\n",
    "        f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TXT', 'TXT', 'TXT', 'TXT', 'TXT', 'TXT', 'TXT']\n"
     ]
    }
   ],
   "source": [
    "print([\"TXT\"] * 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = AssetTypes.URI_FOLDER\n",
    "path = \"azureml://datastores/stocknewsjson/stock-news-json\"\n",
    "input_mode = InputOutputModes.RO_MOUNT\n",
    "output_mode = InputOutputModes.RW_MOUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_component = command(\n",
    "    name=\"data_prep\",\n",
    "    display_name=\"Finding out which blobs to actually use\",\n",
    "    description=\"Loads files from Azure Blob Storage from todays \",\n",
    "    inputs={\n",
    "        \"blob_storage\": Input(mode=InputOutputModes.DIRECT)\n",
    "    },\n",
    "    outputs={\n",
    "        \"prep_output\": Output(type=data_type, mode=output_mode)\n",
    "    },\n",
    "    code=\"./components/prep.py\",\n",
    "    command=\"python prep.py --blob_storage ${{inputs.blob_storage}} --prep_output ${{outputs.prep_output}}\",\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    "    compute=\"ava\",\n",
    "    is_deterministic=\"false\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_component = command(\n",
    "    name=\"data_prep\",\n",
    "    display_name=\"Classify the sentiments of todays stock news\",\n",
    "    description=\"Loads data via AlphaVantage API input, preps data and stores to as data asset\",\n",
    "    inputs={\n",
    "        \"classify_input\": Input(type=data_type, mode=input_mode), \n",
    "    },\n",
    "    outputs={\n",
    "        \"classify_output\": Output(type=data_type, mode=output_mode)\n",
    "    },\n",
    "    code=\"./components/classify.py\",\n",
    "    command=\"python classify.py --classify_input ${{inputs.classify_input}} --classify_output ${{outputs.classify_output}}\",\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    "    compute=\"ava\",\n",
    "    is_deterministic=\"false\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_component = command(\n",
    "    name=\"data_prep\",\n",
    "    display_name=\"Summarize the news\",\n",
    "    description=\"Loads data via AlphaVantage API input, preps data and stores to as data asset\",\n",
    "    inputs={\n",
    "        \"summarize_input\": Input(type=data_type, mode=input_mode),\n",
    "    },\n",
    "    outputs={\n",
    "        \"summarize_output\": Output(type=data_type, mode=output_mode)\n",
    "    },\n",
    "    code=\"./components/summarize.py\",\n",
    "    command=\"python summarize.py --summarize_input ${{inputs.summarize_input}} --summarize_output ${{outputs.summarize_output}}\",\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    "    compute=\"ava\",\n",
    "    is_deterministic=\"false\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.dsl import pipeline\n",
    "\n",
    "@pipeline(compute=\"ava\")\n",
    "def stock_news_pipeline():\n",
    "\n",
    "    data_prep_job = data_prep_component(\n",
    "        blob_storage=\"https://mlstorageleo.blob.core.windows.net/\"\n",
    "    )\n",
    "    classify_job = classify_component(\n",
    "        classify_input=data_prep_job.outputs.prep_output\n",
    "\n",
    "    ) # feed putput of previous step into the training job\n",
    "    summarize_job = summarize_component(\n",
    "        summarize_input = classify_job.outputs.classify_output\n",
    "    )\n",
    "\n",
    "    return {\"processed_file\": summarize_job.outputs.summarize_output}\n",
    "\n",
    "pipeline_job = stock_news_pipeline()\n",
    "\n",
    "# set pipeline level compute\n",
    "pipeline_job.settings.default_compute = \"ava\"\n",
    "pipeline_job.settings.reuse_component = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading summarize.py\u001b[32m (< 1 MB): 100%|##########| 2.98k/2.98k [00:00<00:00, 38.6kB/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>stock-news-analysis-pipeline</td><td>teal_wheel_ghmct9469p</td><td>pipeline</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/teal_wheel_ghmct9469p?wsid=/subscriptions/5a361d37-b562-4eee-981b-0936493063e9/resourcegroups/mlgroup/workspaces/mlworkspace&amp;tid=08548f02-0216-4325-938b-fd30f6829e55\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "PipelineJob({'inputs': {}, 'outputs': {'processed_file': <azure.ai.ml.entities._job.pipeline._io.base.PipelineOutput object at 0x000001C57E3346A0>}, 'jobs': {}, 'component': PipelineComponent({'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': True, 'auto_delete_setting': None, 'name': 'azureml_anonymous', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': 'c:\\\\Users\\\\leopu\\\\OneDrive\\\\Programming\\\\Python\\\\azure\\\\stock-news-analysis\\\\news-analysis-pipeline', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x000001C57E220CD0>, 'version': '1', 'latest_version': None, 'schema': None, 'type': 'pipeline', 'display_name': 'stock_news_pipeline', 'is_deterministic': None, 'inputs': {}, 'outputs': {'processed_file': {}}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {'data_prep_job': Command({'parameters': {}, 'init': False, 'name': 'data_prep_job', 'type': 'command', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': 'c:\\\\Users\\\\leopu\\\\OneDrive\\\\Programming\\\\Python\\\\azure\\\\stock-news-analysis\\\\news-analysis-pipeline', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x000001C57FD7CD90>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'Finding out which blobs to actually use', 'experiment_name': None, 'compute': 'ava', 'services': None, 'comment': None, 'job_inputs': {'blob_storage': {'type': 'uri_folder', 'path': 'https://mlstorageleo.blob.core.windows.net/'}}, 'job_outputs': {'prep_output': {'type': 'uri_folder', 'mode': 'rw_mount'}}, 'inputs': {'blob_storage': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x000001C57E326CD0>}, 'outputs': {'prep_output': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x000001C57FD7CBE0>}, 'component': 'azureml_anonymous:506ccb16-6250-4acc-8b34-b488842ba00c', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': '1133b72f-3861-4bc9-bd69-6b941a4e096d', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'swept': False}), 'classify_job': Command({'parameters': {}, 'init': False, 'name': 'classify_job', 'type': 'command', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': 'c:\\\\Users\\\\leopu\\\\OneDrive\\\\Programming\\\\Python\\\\azure\\\\stock-news-analysis\\\\news-analysis-pipeline', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x000001C57E326C40>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'Classify the sentiments of todays stock news', 'experiment_name': None, 'compute': 'ava', 'services': None, 'comment': None, 'job_inputs': {'classify_input': '${{parent.jobs.data_prep_job.outputs.prep_output}}'}, 'job_outputs': {'classify_output': {'type': 'uri_folder', 'mode': 'rw_mount'}}, 'inputs': {'classify_input': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x000001C57E326D00>}, 'outputs': {'classify_output': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x000001C57E3266A0>}, 'component': 'azureml_anonymous:bcb993fc-0247-4465-9e40-dd2fc31b40f0', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': 'aa70485f-268b-4221-be39-befd42869c03', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'swept': False}), 'summarize_job': Command({'parameters': {}, 'init': False, 'name': 'summarize_job', 'type': 'command', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': 'c:\\\\Users\\\\leopu\\\\OneDrive\\\\Programming\\\\Python\\\\azure\\\\stock-news-analysis\\\\news-analysis-pipeline', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x000001C57E326BE0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'Summarize the news', 'experiment_name': None, 'compute': 'ava', 'services': None, 'comment': None, 'job_inputs': {'summarize_input': '${{parent.jobs.classify_job.outputs.classify_output}}'}, 'job_outputs': {'summarize_output': '${{parent.outputs.processed_file}}'}, 'inputs': {'summarize_input': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x000001C57E326C70>}, 'outputs': {'summarize_output': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x000001C57E326DC0>}, 'component': 'azureml_anonymous:9e2ab8a2-758e-4a32-853d-11523a67f40a', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': '96600392-05db-4cbc-87db-34371dee686c', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'swept': False})}, 'job_types': {'command': 3}, 'job_sources': {'REMOTE.WORKSPACE.COMPONENT': 3}, 'source_job_id': None}), 'type': 'pipeline', 'status': 'Preparing', 'log_files': None, 'name': 'teal_wheel_ghmct9469p', 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'git@github.com:LeonardPuettmann/azure-stock-news-analysis.git', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': 'b7687b3bc63e41f34c584c3f659de9830b1d490b', 'azureml.git.dirty': 'True', 'azureml.DevPlatv2': 'true', 'azureml.DatasetAccessMode': 'Asset', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'MFE', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'True', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.enforceRerun': 'False', 'azureml.defaultComputeName': 'ava', 'azureml.defaultDataStoreName': 'workspaceblobstore', 'azureml.pipelineComponent': 'pipelinerun'}, 'print_as_yaml': True, 'id': '/subscriptions/5a361d37-b562-4eee-981b-0936493063e9/resourceGroups/mlgroup/providers/Microsoft.MachineLearningServices/workspaces/mlworkspace/jobs/teal_wheel_ghmct9469p', 'Resource__source_path': None, 'base_path': 'c:\\\\Users\\\\leopu\\\\OneDrive\\\\Programming\\\\Python\\\\azure\\\\stock-news-analysis\\\\news-analysis-pipeline', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x000001C57E220C40>, 'serialize': <msrest.serialization.Serializer object at 0x000001C57E334910>, 'display_name': 'stock_news_pipeline', 'experiment_name': 'stock-news-analysis-pipeline', 'compute': 'ava', 'services': {'Tracking': {'endpoint': 'azureml://northeurope.api.azureml.ms/mlflow/v1.0/subscriptions/5a361d37-b562-4eee-981b-0936493063e9/resourceGroups/mlgroup/providers/Microsoft.MachineLearningServices/workspaces/mlworkspace?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/teal_wheel_ghmct9469p?wsid=/subscriptions/5a361d37-b562-4eee-981b-0936493063e9/resourcegroups/mlgroup/workspaces/mlworkspace&tid=08548f02-0216-4325-938b-fd30f6829e55', 'type': 'Studio'}}, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submit job to workspace\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline_job, experiment_name=\"stock-news-analysis-pipeline\"\n",
    ")\n",
    "pipeline_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: teal_wheel_ghmct9469p\n",
      "Web View: https://ml.azure.com/runs/teal_wheel_ghmct9469p?wsid=/subscriptions/5a361d37-b562-4eee-981b-0936493063e9/resourcegroups/mlgroup/workspaces/mlworkspace\n",
      "\n",
      "Streaming logs/azureml/executionlogs.txt\n",
      "========================================\n",
      "\n",
      "[2023-07-22 19:45:58Z] Submitting 1 runs, first five are: c870d7d7:b8999d93-35d8-47d4-892f-ede848eb69d0\n",
      "[2023-07-22 19:46:28Z] Completing processing run id b8999d93-35d8-47d4-892f-ede848eb69d0.\n",
      "[2023-07-22 19:46:28Z] Submitting 1 runs, first five are: efba5f2e:f59b90ce-fe5e-48c9-81fe-0246663824d1\n",
      "[2023-07-22 19:48:08Z] Completing processing run id f59b90ce-fe5e-48c9-81fe-0246663824d1.\n",
      "[2023-07-22 19:48:08Z] Submitting 1 runs, first five are: 78f4424f:7ccb0bad-dcae-46ce-a0b8-76cd10a1e7eb\n",
      "[2023-07-22 20:33:12Z] Completing processing run id 7ccb0bad-dcae-46ce-a0b8-76cd10a1e7eb.\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: teal_wheel_ghmct9469p\n",
      "Web View: https://ml.azure.com/runs/teal_wheel_ghmct9469p?wsid=/subscriptions/5a361d37-b562-4eee-981b-0936493063e9/resourcegroups/mlgroup/workspaces/mlworkspace\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Wait until the job completes\n",
    "ml_client.jobs.stream(pipeline_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdk-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
