{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "import constants\n",
    "\n",
    "from azure.ai.ml import command, Input, Output\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import Environment\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "# Get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=constants.SUBSCRIPTION_ID,\n",
    "    resource_group_name=constants.RESOURCE_GROUP_NAME,\n",
    "    workspace_name=constants.WORKSPACE_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16873668\n"
     ]
    }
   ],
   "source": [
    "current_day_timestamp = datetime.datetime.today().timestamp()\n",
    "current_day_timestamp = str(current_day_timestamp)[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting files/prep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile files/prep.py \n",
    "\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "import argparse\n",
    "\n",
    "def main():\n",
    "\n",
    "    parser = argparse.ArgumentParser(\"prep\")\n",
    "    parser.add_argument(\"--prep_data\", type=str, help=\"Path of prepped data\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # log in to the Blob Service Client\n",
    "    account_url = \"https://mlstorageleo.blob.core.windows.net\"\n",
    "    blob_service_client = BlobServiceClient(account_url, account_key=constants.BLOB_KEY)\n",
    "\n",
    "    # connect to the container \n",
    "    container_client = blob_service_client.get_container_client(container=\"stock-news-json\") \n",
    "\n",
    "    # list and download all currently available blobs\n",
    "    blob_list = container_client.list_blobs()\n",
    "\n",
    "    # get the timestamp with the current day \n",
    "    current_day_timestamp = datetime.datetime.today().timestamp()\n",
    "    current_day_timestamp = str(current_day_timestamp)[:8] # first 8 digits are the timestamp of the day\n",
    "\n",
    "    blobs_to_download = [blob.name for blob in blob_list if current_day_timestamp in blob.name]\n",
    "    for blob in blobs_to_download:\n",
    "        download_file_path = os.path.join(args.prep_data, str(blob))\n",
    "        with open(file=download_file_path, mode=\"wb\") as download_file:\n",
    "            download_file.write(container_client.download_blob(blob).readall())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile files/classify.py\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--input_data\", type=str, help=\"path or URL to input data\")\n",
    "# parser.add_argument(\"--output_data\", type=str, help=\"path or URL to output data\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# download distilbert model from HuggingFace\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"KernAI/stock-news-destilbert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"KernAI/stock-news-destilbert\")\n",
    "\n",
    "def main():\n",
    "      #dir_list = os.listdir(args.input_data)\n",
    "      dir_list = \"./data/\"\n",
    "      for file_name in [file for file in os.listdir(dir_list) if file.endswith('.json')]:\n",
    "            with open(dir_list + file_name) as json_file:\n",
    "                  data = json.load(json_file)\n",
    "            texts = data[\"texts\"]\n",
    "\n",
    "            sentiments = []\n",
    "            for text in texts: \n",
    "                  tokenized_text = tokenizer(\n",
    "                        text,\n",
    "                        truncation=True,\n",
    "                        is_split_into_words=False,\n",
    "                        return_tensors=\"pt\"\n",
    "                  )\n",
    "\n",
    "                  outputs = model(tokenized_text[\"input_ids\"])\n",
    "                  outputs_logits = outputs.logits.argmax(1)\n",
    "\n",
    "                  mapping = {0: 'neutral', 1: 'negative', 2: 'positive'}\n",
    "                  predicted_label = mapping[int(outputs_logits[0])]\n",
    "                  sentiments.append(predicted_label)\n",
    "\n",
    "            # add the sentiments to the data\n",
    "            data[\"sentiments\"] = sentiments\n",
    "\n",
    "            # overwrite old files with new files containing the sentiment\n",
    "            with open(dir_list+file_name, \"w\") as f:\n",
    "                  json.dump(data, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "      main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile files/summarize.py\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration, TFPegasusForConditionalGeneration\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--input_data\", type=str, help=\"path or URL to input data\")\n",
    "# parser.add_argument(\"--output_data\", type=str, help=\"path or URL to output data\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# load the model and the tokenizer\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"human-centered-summarization/financial-summarization-pegasus\")\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"human-centered-summarization/financial-summarization-pegasus\") \n",
    "\n",
    "def main():\n",
    "      #dir_list = os.listdir(args.input_data)\n",
    "      dir_list = \"./data/\"\n",
    "      for file_name in [file for file in os.listdir(dir_list) if file.endswith('.json')]:\n",
    "            with open(dir_list + file_name) as json_file:\n",
    "                  data = json.load(json_file)\n",
    "            texts = data[\"texts\"]\n",
    "\n",
    "            summaries = []\n",
    "            for text in texts: \n",
    "                # Tokenize our text\n",
    "                # If you want to run the code in Tensorflow, please remember to return the particular tensors as simply as using return_tensors = 'tf'\n",
    "                input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "                # Generate the output (Here, we use beam search but you can also use any other strategy you like)\n",
    "                output = model.generate(\n",
    "                    input_ids, \n",
    "                    max_length=32, \n",
    "                    num_beams=5, \n",
    "                    early_stopping=True\n",
    "                )\n",
    "\n",
    "                # Finally, we can print the generated summary\n",
    "                summaries.append(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "\n",
    "            # add the sentiments to the data\n",
    "            data[\"summaries\"] = summaries\n",
    "\n",
    "            # overwrite old files with new files containing the sentiment\n",
    "            with open(dir_list+file_name, \"w\") as f:\n",
    "                  json.dump(data, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "      main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "In the past week, AAPL stock has gone up by 0.01%, with a monthly gain of 4.27% and a quarterly surge of 21.86%. The volatility ratio for the week is 2.08%, and the volatility levels for the last 30 days are 1.48% for Apple Inc. The simple moving average for the last 20 days is 3.05% for AAPL stock, with a simple moving average of 18.58% for the last 200 days. Is It Worth Investing in Apple Inc. (NASDAQ: AAPL) Right Now? Apple Inc. (NASDAQ: AAPL) has a price-to-earnings ratio of 30.74x that is above its average ratio. Additionally, the\n",
      "\n",
      "Summarized text:\n",
      "Shares of Apple are trading at a P/E ratio of 30.74x.\n",
      "\n",
      "Original text:\n",
      "What Happened: Shares of fabless chip and software maker Broadcom (NASDAQ:AVGO) jumped 5.5% in the afternoon session after the company is expected to receive conditional approval from the European Union for its $61 billion acquisition of VMware. This approval is subject to Broadcom offering solutions to address antitrust concerns. The news comes amidst ongoing investigations by the U.S. Federal Trade Commission and the UK's antitrust regulator. What is the market telling us: Broadcom's shares are somewhat volatile and over the last year have had 9 moves greater than 5%. In context of that, today's move is indicating the market considers\n",
      "\n",
      "Summarized text:\n",
      "EU expected to give conditional approval this week. Deal is subject to Broadcom offering solutions to address antitrust concerns\n",
      "\n",
      "Original text:\n",
      "The buying and selling of stock by a company’s insider give investors a sense that the stock will rise or fall in the future. DigitalOcean Holdings Inc. shares valued at $450,000 were sold by Norman Harold Matthew on Jun 06. At $45.00 per share, Norman Harold Matthew sold 10,000 shares. The insider’s holdings dropped to 129,890 shares worth approximately $5.56 million following the completion of this transaction. 25-cent Stock Takes $11T Commodities Sector Digital One brilliantly-run technology firm has successfully partnered with some of the largest players in the industry to bring a first-of-its-kind digital solution to the global commodities\n",
      "\n",
      "Summarized text:\n",
      "Norman Harold Matthew sold 10,000 shares at $45.00 per share.\n",
      "\n",
      "Original text:\n",
      "Well, it’s time for another stroll through history. On Saturday, June 3, I took a group of interested people through a two-hour walk along the historical and architectural landmarks of the village of Johnson City. A village built upon the strength of Endicott-Johnson and home to thousands of new arrivals – both immigrants and native-born citizens. It was a sunny day for a walk and the telling of stories of history. I am profusely thankful for the generous notes of village historian Janet Ottman. This Saturday, June 17, it’s time for another walk along the streets of our community. This\n",
      "\n",
      "Summarized text:\n",
      "History walk planned for Saturday, June 17.\n",
      "\n",
      "Original text:\n",
      "Baron Funds, an investment management firm, released its \"Baron Durable Advantage Fund\" first quarter 2023 investor letter, a copy of which can be downloaded here. The Baron Durable Advantage Fund gained 16.0% during the first quarter, compared favorably to its S&P 500 benchmark which earned a 7.5% return for the same period. Spare some time to check the fund’s top 5 holdings to know more about their top bets for 2023. In its Q1 2023 investor letter, Baron Durable Advantage Fund mentioned Microsoft Corporation (NASDAQ:MSFT) and explained its insights for the company. Founded in 1975, Microsoft Corporation (NASDAQ:MSFT) is a\n",
      "\n",
      "Summarized text:\n",
      "Baron Funds’ ‘Baron Advantage Fund’ outperformed S&P 500 in first quarter. Top holdings of the fund include Microsoft\n",
      "\n",
      "Original text:\n",
      "Let's talk about the popular Texas Instruments Incorporated (NASDAQ:TXN). The company's shares saw significant share price movement during recent months on the NASDAQGS, rising to highs of US$186 and falling to the lows of US$161. Some share price movements can give investors a better opportunity to enter into the stock, and potentially buy at a lower price. A question to answer is whether Texas Instruments' current trading price of US$172 reflective of the actual value of the large-cap? Or is it currently undervalued, providing us with the opportunity to buy? Let’s take a look at Texas Instruments’s outlook and value\n",
      "\n",
      "Summarized text:\n",
      "Check out Texas Instruments’s fundamentals to see if it’s undervalued.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PegasusTokenizer.from_pretrained(\"human-centered-summarization/financial-summarization-pegasus\")\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"human-centered-summarization/financial-summarization-pegasus\") \n",
    "\n",
    "def main():\n",
    "    #dir_list = os.listdir(args.input_data)\n",
    "    dir_list = \"./data/\"\n",
    "    for file_name in [file for file in os.listdir(dir_list) if file.endswith('.json')]:\n",
    "        with open(dir_list + file_name) as json_file:\n",
    "                data = json.load(json_file)\n",
    "        texts = data[\"texts\"]\n",
    "\n",
    "        input_ids = tokenizer(texts[0], return_tensors=\"pt\").input_ids\n",
    "\n",
    "        # Generate the output (Here, we use beam search but you can also use any other strategy you like)\n",
    "        output = model.generate(\n",
    "            input_ids, \n",
    "            max_length=32, \n",
    "            num_beams=5, \n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "        # Finally, we can print the generated summary\n",
    "        print(\"Original text:\")\n",
    "        print(texts[0]+\"\\n\")\n",
    "        print(\"Summarized text:\")\n",
    "        print(tokenizer.decode(output[0], skip_special_tokens=True)+ \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "      main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Some text to summarize here\n",
    "text_to_summarize = \"National Commercial Bank (NCB), Saudi Arabia’s largest lender by assets, agreed to buy rival Samba Financial Group for $15 billion in the biggest banking takeover this year.NCB will pay 28.45 riyals ($7.58) for each Samba share, according to a statement on Sunday, valuing it at about 55.7 billion riyals. NCB will offer 0.739 new shares for each Samba share, at the lower end of the 0.736-0.787 ratio the banks set when they signed an initial framework agreement in June.The offer is a 3.5% premium to Samba’s Oct. 8 closing price of 27.50 riyals and about 24% higher than the level the shares traded at before the talks were made public. Bloomberg News first reported the merger discussions.The new bank will have total assets of more than $220 billion, creating the Gulf region’s third-largest lender. The entity’s $46 billion market capitalization nearly matches that of Qatar National Bank QPSC, which is still the Middle East’s biggest lender with about $268 billion of assets.\"\n",
    "\n",
    "\n",
    "# Generated Output: Saudi bank to pay a 3.5% premium to Samba share price. Gulf region’s third-largest lender will have total assets of $220 billion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile files/store.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdk-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
